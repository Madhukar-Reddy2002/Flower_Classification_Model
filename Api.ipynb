{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabcode import ColabCode\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: C:\\Users\\madhu\\AppData\\Local/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken 2cNVnDEt0N2Cyhe07s7wvLZcH7H_4BeSM2pxWXtvgqxePsfzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: NgrokTunnel: \"https://8f39-103-18-165-128.ngrok-free.app\" -> \"http://localhost:12000\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [6720]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60930 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60930 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60930 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:60930 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:60940 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60940 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966ms/step\n",
      "INFO:     127.0.0.1:60955 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [6720]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Provide the path to your saved model file\n",
    "model_path = \"./MyModel.h5\"\n",
    "\n",
    "# Load the model\n",
    "MODEL = load_model(model_path)\n",
    "cc = ColabCode(port=12000, code=False)\n",
    "\n",
    "CLASS_NAMES = ['balloon flower', 'black-eyed susan', 'foxglove', 'frangipani', 'jasmine', 'lotus lotus', 'orange hibiscus', 'orange marigold', 'oxeye daisy', 'pink hibiscus', 'pink rose', 'red hibiscus', 'redRose', 'stemless gentian', 'sunflower', 'thorn apple', 'water lily', 'yellow hibiscus', 'yellow marigold', 'yellow rose']\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def get_model():\n",
    "    return MODEL\n",
    "\n",
    "# Use the CORS middleware to allow all origins, methods, and headers\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read():\n",
    "    return \"I am live\"\n",
    "\n",
    "def read_file_as_image(data) -> np.ndarray:\n",
    "    try:\n",
    "        image = Image.open(BytesIO(data))\n",
    "        # Resize the image to match the expected input shape (240, 240)\n",
    "        image = image.resize((250, 250))\n",
    "        image = np.array(image)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Error reading image: {str(e)}\")\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(\n",
    "    file: UploadFile = File(..., content_type=\"image/jpeg\"),\n",
    "    model: tf.keras.Model = Depends(get_model)\n",
    "):\n",
    "    try:\n",
    "        image = read_file_as_image(await file.read())\n",
    "        image_batch = np.expand_dims(image, 0)\n",
    "        prediction = model.predict(image_batch)\n",
    "        predicted_class = CLASS_NAMES[np.argmax(prediction[0])]\n",
    "        confidence = float(np.max(prediction[0]))\n",
    "        return {\n",
    "            \"class\": predicted_class,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Prediction error: {str(e)}\")\n",
    "cc.run_app(app=app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
